# # version: '3'
# services:
#   redis:
#     image: redis/redis-stack-server
#     container_name: pipek-redis
#     volumes:
#       - redis_data:/data
#     restart: always
#     networks:
#       - default
#     logging:
#       options:
#         max-size: "10m"
#         max-file: "3"

#   airflow-webserver:
#         hostname: airflow
#         container_name: airflow
#         image: andrejunior/airflow-spark:latest
#         restart: always
#         networks:
#             # - airflow
#             - default
#         depends_on:
#             - postgresql
#         environment:   
#             - AIRFLOW__CORE__LOAD_EXAMPLES=False
#             - LOAD_EX=n
#             - EXECUTOR=Local    
#         volumes:
#             - airflow-data:/usr/local/airflow/data
#             - ./src/dags:/usr/local/airflow/dags
#             - ./src/applications:/usr/local/spark/applications            
#             - ./src/assets:/usr/local/spark/assets     
#         ports:
#             - "8085:8080"
#         # command: webserver
#         command: ["airflow", "webserver"]
#         healthcheck:
#             # test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
#             test: ["CMD-SHELL", "curl -f http://localhost:8080/ || exit 1"]
#             interval: 30s
#             timeout: 30s
#             retries: 3

#   postgresql:
#     # image: docker.io/library/postgres:16
#     image: postgres:16
#     restart: unless-stopped
#     healthcheck:
#       test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
#       start_period: 20s
#       interval: 60s
#       retries: 5
#       timeout: 5s
#     ports:
#       - 5432:5432
#     volumes:
#       - postgresql_data:/var/lib/postgresql/data
#     environment:
#       - POSTGRES_PASSWORD=CoEpasswd
#       - POSTGRES_USER=coe
#       - POSTGRES_DB=aies_dashdb
#     # environment:
#     #         POSTGRES_USER: 'airflow'
#     #         POSTGRES_PASSWORD: 'airflow'
#     #         POSTGRES_DB: 'airflow'
#     #         PGDATA: /data/postgres
#     logging:
#       options:
#         max-size: "10m"
#         max-file: "3"


#   web:
#     build: .
#     image: pipek-image
#     container_name: pipek-web
#     volumes:
#       - /etc/localtime:/etc/localtime:ro
#       - ./:/app
#     ports:
#       - 8080:8080
#     links:
#       - redis
#       - airflow-webserver
#     depends_on:
#       - redis
#       - airflow-webserver
#     networks:
#       - default
#     restart: always
#     environment:
#       PIPEK_ENV: /app/.env.dev
#     env_file:
#       - .env.dev
#     command: 
#       /venv/bin/pipek-dash -H 0.0.0.0 --port 8080 -d
#     logging:
#       options:
#         max-size: "10m"
#         max-file: "3"

#   controller:
#     build: .
#     image: pipek-image
#     container_name: pipek-controller
#     volumes:
#       - /etc/localtime:/etc/localtime:ro
#       - ./:/app
#     links:
#       - redis
#       - airflow-webserver
#     depends_on:
#       - redis
#       - airflow-webserver
#     networks:
#       - default
#     restart: always
#     environment:
#       PIPEK_ENV: /app/.env.dev
#     env_file:
#       - .env.dev
#     command:
#       /venv/bin/pipek-controller

#     logging:
#       options:
#         max-size: "10m"
#         max-file: "3"


#   worker:
#     build: .
#     image: pipek-image
#     container_name: pipek-worker
#     volumes:
#       - /etc/localtime:/etc/localtime:ro
#       - ./:/app
#     depends_on:
#       - redis
#       - airflow-webserver
#     links:
#       - redis
#       - airflow-webserver
#     restart: always
#     env_file:
#       - .env.dev
#     environment:
#       PIPEK_ENV: /app/.env.dev
#     command:
#       /venv/bin/pipek-worker
#     logging:
#       options:
#         max-size: "10m"
#         max-file: "3"


# networks:
#   default:

# volumes:
#   redis_data:
#   postgresql_data:
#   airflow-data:





version: '3'
services:
  redis:
    image: redis/redis-stack-server
    container_name: pipek-redis
    volumes:
      - redis_data:/data
    restart: always
    networks:
      - default
    logging:
      options:
        max-size: "10m"
        max-file: "3"

  postgresql:
    image: docker.io/library/postgres:16
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
      start_period: 20s
      interval: 60s
      retries: 5
      timeout: 5s
    ports:
      - 5432:5432
    volumes:
      - postgresql_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_PASSWORD=CoEpasswd
      - POSTGRES_USER=coe
      - POSTGRES_DB=aies_dashdb
    logging:
      options:
        max-size: "10m"
        max-file: "3"

  web:
    build: .
    image: pipek-image
    container_name: pipek-web
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./:/app
    ports:
      - 8080:8080
    links:
      - redis
    depends_on:
      - redis
    networks:
      - default
    restart: always
    environment:
      PIPEK_ENV: /app/.env.dev
    env_file:
      - .env.dev
    command: 
      /venv/bin/pipek-dash -H 0.0.0.0 --port 8080 -d
    logging:
      options:
        max-size: "10m"
        max-file: "3"

  controller:
    build: .
    image: pipek-image
    container_name: pipek-controller
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./:/app
    links:
      - redis
    depends_on:
      - redis
    networks:
      - default
    restart: always
    environment:
      PIPEK_ENV: /app/.env.dev
    env_file:
      - .env.dev
    command:
      /venv/bin/pipek-controller
    logging:
      options:
        max-size: "10m"
        max-file: "3"

  worker:
    build: .
    image: pipek-image
    container_name: pipek-worker
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./:/app
    depends_on:
      - redis
    links:
      - redis
    restart: always
    env_file:
      - .env.dev
    environment:
      PIPEK_ENV: /app/.env.dev
    command:
      /venv/bin/pipek-worker
    logging:
      options:
        max-size: "10m"
        max-file: "3"

  # Airflow services
  airflow-webserver:
    hostname: airflow
    container_name: airflow-webserver
    image: andrejunior/airflow-spark:latest
    restart: always
    networks:
      - airflow
    depends_on:
      - airflow-postgres
      - minio
      - spark-master
      - spark-worker
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - LOAD_EX=n
      - EXECUTOR=Local
    volumes:
      - airflow-data:/usr/local/airflow/data
      - ./src/dags:/usr/local/airflow/dags
      # - ./src/spark/applications:/usr/local/spark/applications
      # - ./src/spark/assets:/usr/local/spark/assets
      - ./src/applications:/usr/local/spark/applications
      - ./src/assets:/usr/local/spark/assets
    ports:
      - "8085:8080"
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  airflow-postgres:
    hostname: airflow-postgres
    container_name: airflow-postgres
    image: 'postgres:14-bullseye'
    environment:
      POSTGRES_USER: 'airflow'
      POSTGRES_PASSWORD: 'airflow'
      POSTGRES_DB: 'airflow'
      PGDATA: /data/postgres
    volumes:
      - airflow-postgres:/data/postgres
    ports:
      - "5433:5432"
    networks:
      - airflow
    restart: on-failure
    healthcheck:
      test: ["CMD", "pg_isready"]
      interval: 60s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 400MB

  minio:
    hostname: bucket
    container_name: bucket
    image: 'bitnami/minio:latest'
    environment:
      MINIO_ROOT_USER: airflow
      MINIO_ROOT_PASSWORD: airflow
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - minio_data:/data
    networks:
      - airflow
    healthcheck:
      test: ["CMD", "curl", "-f", "http://bucket:9000/minio/health/live"]
      interval: 60s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 400MB

  createbuckets:
    image: minio/mc
    networks:
      - airflow
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add myminio http://bucket:9000 airflow airflow;
      /usr/bin/mc rm -r --force myminio/airflow;
      /usr/bin/mc mb myminio/airflow;
      /usr/bin/mc policy download myminio/airflow;
      exit 0;
      "

  spark-master:
    image: bitnami/spark:3.2.1
    user: root
    hostname: spark-master
    container_name: spark-master
    networks:
      - airflow
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./src/spark/applications:/usr/local/spark/applications
      - ./src/spark/assets:/usr/local/spark/assets
    ports:
      - "8081:8080"
      - "7077:7077"
    deploy:
      resources:
        limits:
          memory: 500MB

  spark-worker:
    image: bitnami/spark:3.2.1
    user: root
    hostname: spark-worker
    container_name: spark-worker
    networks:
      - airflow
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./src/spark/applications:/usr/local/spark/applications
      - ./src/spark/assets:/usr/local/spark/assets
    depends_on:
      - spark-master
    deploy:
      resources:
        limits:
          memory: 1GB

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: 6410110625@gmail.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    networks:
      - airflow
    depends_on:
      - airflow-postgres

# Networks and volumes shared by all services
networks:
  default:
  airflow:
    driver: bridge

volumes:
  redis_data:
  postgresql_data:
  airflow-data:
  airflow-postgres:
  minio_data:
